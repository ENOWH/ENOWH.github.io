---
title: "Chapter01"
excerpt: "머신러닝 Chap01 전체 흐름"

categories:
  - MachineLearning
tags:
  - [Machine Learning, 머신러닝]

permalink: /categories/MachineLearning/Chapter01_MachineLearning

toc: true
toc_sticky: true

date: 2025-04-20
last_modified_at: 2025-04-20
---

# 📘 Session 1: Course Introduction (페이지 1–15)

## 📌 세션 개요

이 세션은 머신러닝의 전반적인 개요와 문제 정의를 다루며,  
- 머신러닝이란 무엇인가  
- 지도학습의 수학적 표현  
- 경험적 위험 최소화 (ERM: Empirical Risk Minimization)  
- 과적합, 일반화, 모델 복잡도, 정규화 등  
기본적인 개념들을 포괄적으로 소개한다.

---

## ✅ 핵심 개념 정리

### 🔹 What is Machine Learning?
- 데이터를 바탕으로 **패턴을 학습하고 예측을 수행**하는 시스템
- 경험을 통해 성능을 향상시키는 알고리즘

---

### 🔹 Supervised Learning
- **입력-출력 쌍** $begin:math:text$(x_i, y_i)$end:math:text$ 를 통해 함수 $begin:math:text$f: \\mathcal{X} \\to \\mathcal{Y}$end:math:text$를 학습
- 목표: 주어진 $begin:math:text$x$end:math:text$에 대해 정답 $begin:math:text$y$end:math:text$를 예측하는 함수 $begin:math:text$f$end:math:text$를 찾는 것

---

### 🔹 Regression vs. Classification
- **Regression**: 출력 $begin:math:text$ y \\in \\mathbb{R} $end:math:text$ (연속적)
- **Classification**: 출력 $begin:math:text$ y \\in \\{1, \\dots, C\\} $end:math:text$ (이산적)

---

### 🔹 Empirical Risk Minimization (ERM)
- **Loss function** $begin:math:text$ \\ell(y, f(x)) $end:math:text$ 을 기반으로, 평균 손실을 최소화하는 파라미터 $begin:math:text$ \\theta $end:math:text$를 찾음

#### ERM 수식:
$$
\hat{R}(\theta) = \frac{1}{n} \sum_{i=1}^n \ell(y_i, f_\theta(x_i))
$$

---

### 🔹 Overfitting vs. Underfitting
- **Overfitting**: 학습 데이터에는 잘 맞지만, 새로운 데이터에 일반화되지 않음  
- **Underfitting**: 학습 데이터에도 제대로 맞지 않음  
- 일반화 오류는 훈련 오류와 다를 수 있음

---

### 🔹 Regularization (정규화)
- **모델 복잡도 제어**를 통해 overfitting 방지
- 예시: L2 정규화 (Ridge)

#### Regularized ERM 수식:
$$
\hat{R}_{\text{reg}}(\theta) = \frac{1}{n} \sum_{i=1}^n \ell(y_i, f_\theta(x_i)) + \lambda \|\theta\|^2
$$

---

### 🔹 Bias-Variance Tradeoff
- **Bias**: 모델이 단순할수록 생기는 오차
- **Variance**: 모델이 복잡할수록 데이터에 민감하게 반응하는 경향
- 적절한 모델 복잡도를 선택하는 것이 핵심

---

## 🔁 세션 흐름 요약

1. 머신러닝 문제를 함수 근사 문제로 수학적으로 모델링  
2. 경험적 위험 최소화(ERM)를 통해 학습의 목표를 수식으로 표현  
3. 오버피팅과 언더피팅 개념을 통해 일반화 성능의 중요성을 이해  
4. 정규화(Regularization)와 Bias-Variance 관점을 도입하여  
   적절한 모델 선택의 기준을 학습함

---

> 🧠 이 세션은 머신러닝 전반을 이해하기 위한 기초 개념을 정리하고,  
> 이후 최적화와 분류 알고리즘으로 연결되는 이론적 기반을 마련해줌.

# 📘 Session 1: Course Introduction (페이지 1–15)

## 📌 세션 개요

이 세션은 머신러닝의 기본 개념과 분류 체계를 소개하고,  
“무엇이 머신러닝인가?”라는 질문에 답하면서  
**지도학습(supervised)**, **비지도학습(unsupervised)**,  
그리고 **약한 지도학습(weakly supervised)**의 개념을 설명한다.  
또한 모델 설계 관점에서 머신러닝 방법을 **Generative vs Discriminative**,  
**Parametric vs Nonparametric**, **Linear vs Nonlinear** 등으로 분류한다.

---

## ✅ 핵심 개념 정리

### 🔹 What is Machine Learning?
- **정의**: 데이터를 바탕으로 정량적인 추론 및 예측을 수행하는 학문
- **배경**: 통계학, 인공지능, 신호처리 등에서 유래

---

### 🔹 Feature & Feature Vector
- **Feature**: 관측 대상의 수치적 특성 (예: 키, 몸무게 등)
- **Feature Vector**:
  \[
  x = \begin{bmatrix} x_1 \\ \vdots \\ x_d \end{bmatrix} \in \mathbb{R}^d
  \]
- **Synonyms**: data point, instance, example, signal, input 등

---

### 🔹 Categories of Learning
- **Supervised Learning**
  - 학습 데이터: \((x_1, y_1), \dots, (x_n, y_n)\)
  - 분류(classification), 회귀(regression)
- **Unsupervised Learning**
  - 정답(label) 없이 데이터 구조 분석
  - 클러스터링, 차원 축소, 밀도 추정 등
- **Weakly Supervised Learning**
  - 부분적으로 라벨된 데이터 사용 (예: semi-supervised)

---

### 🔹 Supervised Learning: Classification vs Regression
- **Classification**: 출력 \( y \in \{1, \dots, C\} \) (유한 클래스)
- **Regression**: 출력 \( y \in \mathbb{R} \) (연속적 값)

---

### 🔹 Modeling Paradigms in ML
- **Generative vs Discriminative**
  - Generative: 데이터의 전체 분포를 모델링 (예: Naive Bayes)
  - Discriminative: 결정 경계만 모델링 (예: Logistic Regression)
- **Parametric vs Nonparametric**
  - Parametric: 파라미터 수가 고정됨
  - Nonparametric: 데이터가 많아질수록 모델 복잡도 증가
- **Linear vs Nonlinear**
  - Linear: 출력이 입력의 선형함수
  - Nonlinear: 비선형 관계를 모델링

---

### 🔹 Practical Constraints
- **Scalability**: 대규모 데이터/모델에 적합해야 함
- **Privacy, Fairness, Safety**: 실제 응용에서 중요한 비기술적 제약

---

## 🔁 세션 흐름 요약

1. 머신러닝이 다루는 문제 정의와 배경 소개
2. Feature, Feature Vector 개념 및 용어 정리
3. 학습 방식 분류: 지도/비지도/약한 지도학습
4. 분류(Classification)와 회귀(Regression) 구분
5. 모델 설계 관점에서 여러 기준(Generative vs Discriminative 등) 소개
6. 실제 시스템 설계 시 고려해야 할 제약 조건까지 포괄적으로 다룸

---

🧠 이 세션은 최적화 문제로 들어가기 전, 머신러닝이라는 분야의 전반적인 구조를 잡아주는 역할을 함.



# 📗 Session 2: Unconstrained Optimization (페이지 16–45)

## 📌 세션 개요

이 세션은 머신러닝 모델 학습의 핵심인 **최적화 문제(Optimization Problem)**를 수학적으로 정의하고,  
기초적인 **미분 조건**, **Gradient**, **Hessian**, **Taylor Expansion** 등을 기반으로  
최소값을 찾기 위한 조건을 살펴본다.  
또한 로지스틱 회귀(Logistic Regression) 문제를 실제 예시로 들어 **손실 함수**, **gradient**, **Hessian** 계산법을 배운다.

---

# 📗 Session 2: Unconstrained Optimization (페이지 16–45)

## 📌 세션 개요

이 세션은 머신러닝 모델 학습의 핵심인 **최적화 문제(Optimization Problem)**를 수학적으로 정의하고,  
기초적인 **미분 조건**, **Gradient**, **Hessian**, **Taylor Expansion** 등을 기반으로  
최소값을 찾기 위한 조건을 살펴본다.  
또한 로지스틱 회귀(Logistic Regression) 문제를 실제 예시로 들어 **손실 함수**, **gradient**, **Hessian** 계산법을 배운다.

---

## ✅ 핵심 개념 정리

### 🔹 Optimization Problem (최적화 문제)
- **정의**:
  ```
  min_{x ∈ ℝ^d} f(x)
  ```
- **설명**: 목적 함수 f(x)를 최소화하는 x를 찾는 문제

---

### 🔹 Global vs. Local Minimum
- **Global Minimum**:
  ```
  f(x*) ≤ f(x), ∀ x ∈ ℝ^d
  ```
- **Local Minimum**:
  ```
  f(x*) ≤ f(x), ∀ x ∈ neighborhood(x*)
  ```

---

### 🔹 Gradient (기울기)
- **정의**: 목적 함수의 1차 미분값, 함수가 가장 가파르게 증가하는 방향
  ```
  ∇f(x) = [ ∂f/∂x₁, ..., ∂f/∂x_d ]ᵀ
  ```

---

### 🔹 Hessian (헤세 행렬)
- **정의**: 목적 함수의 2차 편미분값으로 구성된 대칭 행렬
  ```
  ∇²f(x) = [ ∂²f / ∂x_i ∂x_j ]_{i,j}
  ```

---

### 🔹 Optimality Conditions (최적 조건)
- **필요조건**:
  ```
  ∇f(x*) = 0
  ```
- **충분조건**:
  ```
  ∇²f(x*) ≻ 0  (positive definite)
  ```

---

### 🔹 Taylor Expansion (2차 테일러 근사)
- **식**:
  ```
  f(x + Δx) ≈ f(x) + ∇f(x)ᵀ Δx + ½ Δxᵀ ∇²f(x) Δx
  ```

---

### 🔹 Logistic Regression Loss (Negative Log Likelihood)
- **식**:
  ```
  min_θ ∑_{i=1}^n log(1 + exp(−yᵢ θᵀ xᵢ))
  ```

---

### 🔹 Regularized Logistic Regression
- **L2 정규화 포함**:
  ```
  min_θ ∑_{i=1}^n log(1 + exp(−yᵢ θᵀ xᵢ)) + λ ||θ||²
  ```

---

### 🔹 Gradient of Logistic Loss
- **식**:
  ```
  ∇θ f(θ) = ∑_{i=1}^n (σ(θᵀ xᵢ) − yᵢ) xᵢ
  ```
  where:
  ```
  σ(z) = 1 / (1 + exp(−z))
  ```

---

### 🔹 Hessian of Logistic Loss
- **식**:
  ```
  ∇²f(θ) = ∑_{i=1}^n σ(θᵀ xᵢ)(1 − σ(θᵀ xᵢ)) xᵢ xᵢᵀ
  ```

---

## 🔁 세션 흐름 요약

1. 머신러닝 학습 문제를 **최적화 문제**로 수학적으로 표현  
2. **Gradient**와 **Hessian**을 통해 극값 조건을 정의  
3. **Taylor 전개**로 최적화 방향과 양의 정부호 조건 도입  
4. 로지스틱 회귀를 실제 예로 들어 손실 함수 정의,  
   gradient 및 Hessian 계산 방법을 학습함  
5. 다음 세션(Iterative Algorithm)에서 Newton's method로 연결될 기초 완성

---

> 🧠 이 세션은 최적화 이론의 핵심 개념을 정립하고,  
> 다음 단계에서 반복 최적화 알고리즘을 적용할 수 있는 **수학적 도구**를 마련해줌.


# 📘 Session 3: Iterative Algorithms for Continuous Optimization (페이지 46–89)

## 📌 세션 개요

이 세션에서는 **최적화 알고리즘의 핵심 구조**를 이해하고,  
대표적인 반복 최적화 기법인  
- **Gradient Descent (GD)**  
- **Newton’s Method**  
- **Quasi-Newton (특히 BFGS)**  
의 개념과 수식, 구현 구조를 비교한다.  
또한 **Line Search**를 이용한 step size 조절과 각 알고리즘의 **수렴 속도 차이**도 함께 배운다.

---

## ✅ 핵심 개념 정리

### 🔹 General Form of Iterative Optimization
- **업데이트 식**:
  ```
  x^{(k+1)} = x^{(k)} + α^{(k)} p^{(k)}
  ```
- **설명**:
  - $begin:math:text$ p^{(k)} $end:math:text$: 이동 방향 (descent direction)
  - $begin:math:text$ α^{(k)} $end:math:text$: step size (learning rate)

---

### 🔹 Descent Direction (감소 방향)
- **조건**:
  ```
  ∇f(x)^T p < 0
  ```
- **설명**: 목적 함수를 줄일 수 있는 방향이면 descent direction이라 부름

---

### 🔹 Gradient Descent (GD)
- **업데이트 식**:
  ```
  x^{(k+1)} = x^{(k)} − α^{(k)} ∇f(x^{(k)})
  ```
- **설명**:
  - 가장 단순한 알고리즘
  - 계산은 쉽지만 수렴 속도는 느릴 수 있음

---

### 🔹 Newton's Method
- **업데이트 식**:
  ```
  x^{(k+1)} = x^{(k)} − [∇²f(x^{(k)})]⁻¹ ∇f(x^{(k)})
  ```
- **설명**:
  - 2차 테일러 근사를 이용한 빠른 수렴
  - 계산 복잡도는 높음 (Hessian 필요)

---

### 🔹 Quasi-Newton Method (e.g., BFGS)
- **업데이트 방향**:
  ```
  p^{(k)} = − B_k⁻¹ ∇f(x^{(k)})
  ```
- **BFGS 업데이트 식**:
  ```
  B_{k+1} = B_k + (y_k y_k^T) / (y_k^T s_k) − (B_k s_k s_k^T B_k) / (s_k^T B_k s_k)
  ```
  where:
  ```
  s_k = x^{(k+1)} − x^{(k)}
  y_k = ∇f(x^{(k+1)}) − ∇f(x^{(k)})
  ```
- **설명**:
  - Hessian을 계산하지 않고 근사
  - 실무에서 자주 사용됨 (예: SciPy `BFGS`)

---

### 🔹 Taylor Expansion (복습)
- **2차 근사 식**:
  ```
  f(x + Δx) ≈ f(x) + ∇f(x)^T Δx + ½ Δx^T ∇²f(x) Δx
  ```
- Newton Method는 이를 기반으로 파라미터 업데이트를 계산함

---

### 🔹 Line Search (Backtracking)
- **조건**:
  ```
  f(x + α p) ≤ f(x) + c α ∇f(x)^T p
  ```
- **설명**:
  - 적절한 step size α를 찾기 위해 반복적으로 줄여가며 만족 조건을 검사
  - 안정적인 수렴을 위해 모든 최적화 알고리즘에서 자주 사용

---

### 🔹 Convergence Rates
- **Gradient Descent**: Linear convergence  
- **Newton’s Method**: Quadratic convergence  
- **Quasi-Newton (BFGS)**: Superlinear convergence

---

## 🔁 세션 흐름 요약

1. 모든 반복 최적화 알고리즘의 **공통 구조**를 먼저 이해  
2. **Gradient Descent** → 단순하고 직관적이지만 느릴 수 있음  
3. **Newton’s Method** → 빠르지만 계산량 큼  
4. **Quasi-Newton (BFGS)** → 계산 효율과 수렴 속도의 절충안  
5. **Line Search**로 안정성 확보  
6. 각각의 방법이 **어떤 정보(gradient, Hessian)를 활용하는지**,  
   그리고 수렴 속도가 어떻게 다른지를 비교함

---

> 🧠 이 세션은 “어떻게 최적화할 것인가?”라는 실전적 질문에 답하면서,  
> 머신러닝 모델 학습의 기초 연산이 되는 알고리즘들의 구조를 정립해줌.


# 📙 Session 4: Nearest Neighbor Classifier (페이지 90–99)

## 📌 세션 개요

이 세션은 **K-최근접 이웃(K-Nearest Neighbor, K-NN)** 알고리즘을 다룬다.  
K-NN은 학습을 하지 않고, 단순히 **저장된 데이터**를 기준으로 가장 가까운 K개의 이웃의 라벨을 이용해  
예측을 수행하는 **비모수적(non-parametric)** 분류기다.  
또한 **거리 기반 분류의 한계점**과 **차원의 저주**, **bias-variance tradeoff**에 대해서도 설명한다.

---

## ✅ 핵심 개념 정리

### 🔹 1-Nearest Neighbor (1-NN)
- **정의**:
  ```
  ŷ(x) = y_{i*}, where i* = argmin_i ||x − x_i||_2
  ```
- **설명**: 입력 x에 대해 가장 가까운 학습 샘플의 라벨 y를 그대로 예측함

---

### 🔹 K-Nearest Neighbor (K-NN)
- **정의**:
  ```
  ŷ(x) = majority_vote { y_i | i ∈ 𝒩_K(x) }
  ```
  where:
  - $begin:math:text$ 𝒩_K(x) $end:math:text$: x의 K-최근접 이웃 인덱스 집합

- **설명**: K개의 가장 가까운 훈련 샘플을 찾고, 그들의 라벨을 기준으로 다수결로 예측

---

### 🔹 Distance Metrics (거리 척도)
- **Euclidean (L2)**:
  ```
  ||x − x_i||_2 = sqrt(∑_{j=1}^d (x_j − x_{ij})²)
  ```
- **Manhattan (L1)**:
  ```
  ∑ |x_j − x_{ij}|
  ```
- **Cosine distance**, **Mahalanobis distance** 등도 존재함

---

### 🔹 Curse of Dimensionality (차원의 저주)
- **설명**:
  - 차원이 높아질수록 모든 데이터 포인트들이 멀어진다  
  - K-NN처럼 거리 기반 알고리즘은 차원이 높을수록 정확도가 낮아질 수 있음

---

### 🔹 Bias-Variance Tradeoff in K-NN
- **설명**:
  - K가 작을수록 **모델이 민감**해짐 → **low bias, high variance**
  - K가 클수록 **모델이 부드러워짐** → **high bias, low variance**
  - 따라서 적절한 K 선택은 성능에 큰 영향을 준다

---

## 🔁 세션 흐름 요약

1. 가장 간단한 분류기인 **1-NN** 소개 → 가장 가까운 이웃의 라벨을 따름  
2. **K-NN** 일반화 → K개의 이웃 기반으로 예측  
3. 거리 계산 기준이 예측 성능에 큰 영향을 준다는 점 강조  
4. 고차원 데이터일수록 거리 기반 분류기의 성능 저하 (차원의 저주)  
5. K 값을 조절하면서 생기는 **bias-variance tradeoff**를 분석함

---

> 🧠 이 세션은 머신러닝의 **비모수적 학습(non-parametric learning)**의 기초를 제공하며,  
> 매우 단순하지만 강력한 K-NN 분류기의 작동 원리와 한계를 학습함.



좋아! 그럼 바로 이어서 다음 세션 정리 들어갈게 — 이 세션부터는 진짜 수학적 최적화의 본론으로 들어가는 파트야. 너가 특히 중요하게 여기는 개념 ↔ 수식 연결도 철저히 정리해줄게.

⸻

📘 Session 2: Unconstrained Optimization (16–45페이지)

🔁 전체 세션 흐름 요약:

이 세션은 “제약 없는 최적화(Unconstrained Optimization)”를 다루며,
최소화 문제의 기본 개념, 필요충분조건, 그래디언트/헤세 행렬,
그리고 **로지스틱 회귀(Logistic Regression)**의 손실 함수 형태까지 다룸.

⸻

📌 개념 1: Optimization Problem (최적화 문제)
	•	정의:
\min_{x \in \mathbb{R}^d} f(x)
	•	설명: 어떤 목적 함수 f(x)를 최소화하는 x를 찾는 문제. 이때 제약 조건은 없음 (Unconstrained).

⸻

📌 개념 2: Local vs. Global Minimum
	•	정의:
	•	Global minimum: f(x^*) \leq f(x), \forall x
	•	Local minimum: f(x^) \leq f(x), \forall x \in \mathcal{B}(x^)
	•	설명: 지역 최솟값은 주변에서만 최소, 전역 최솟값은 전체 영역에서 최소

⸻

📌 개념 3: Gradient (기울기)
	•	정의: 목적 함수 f(x)의 변화 방향과 크기를 나타내는 벡터
	•	수식:
\nabla f(x) = \begin{bmatrix}
\frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_d}
\end{bmatrix}^\top
	•	설명: \nabla f(x)가 0인 점은 (국소적) 극값일 가능성이 있음

⸻

📌 개념 4: Hessian Matrix (헤세 행렬)
	•	정의: f(x)의 2차 미분값들을 모은 대칭 행렬
	•	수식:
\nabla^2 f(x) = \left[ \frac{\partial^2 f}{\partial x_i \partial x_j} \right]_{i,j}
	•	설명: 함수의 곡률(curvature)을 나타냄 → 최적점이 최소인지 최대인지 판단할 수 있음

⸻

📌 개념 5: Second Order Optimality Conditions
	•	필요조건:
\nabla f(x^*) = 0
	•	충분조건:
\nabla^2 f(x^*) \succ 0 \quad (\text{positive definite})
	•	설명:
	•	기울기 = 0이면 극값 후보
	•	헤세 행렬이 양의 정부호면 그 점은 지역 최소값

⸻

📌 개념 6: Taylor Approximation (테일러 전개)
	•	수식:
f(x + \Delta x) \approx f(x) + \nabla f(x)^\top \Delta x + \frac{1}{2} \Delta x^\top \nabla^2 f(x) \Delta x
	•	설명: 최적화 시, 목적 함수를 로컬 근방에서 2차 근사할 때 사용

⸻

📌 개념 7: Logistic Regression Objective (Negative Log Likelihood)
	•	수식:
\min_\theta \sum_{i=1}^n \log(1 + e^{-y_i \theta^\top x_i})
	•	또는 log loss 형태:
\ell(y, f(x)) = \log(1 + e^{-y f(x)})
	•	설명: 로지스틱 회귀의 손실 함수. convex하고 smooth함.

⸻

📌 개념 8: Regularized Logistic Regression
	•	수식:
\min_\theta \sum_{i=1}^n \log(1 + e^{-y_i \theta^\top x_i}) + \lambda \|\theta\|^2
	•	설명: 오버피팅 방지를 위한 L2 정규화 포함

⸻

📌 개념 9: Gradient and Hessian of Logistic Regression
	•	Gradient:
\nabla_\theta f(\theta) = \sum_{i=1}^n \left( \sigma(\theta^\top x_i) - y_i \right) x_i
	•	Hessian:
\nabla^2 f(\theta) = \sum_{i=1}^n \sigma(\theta^\top x_i)(1 - \sigma(\theta^\top x_i)) x_i x_i^\top
	•	설명:
	•	sigmoid: \sigma(z) = \frac{1}{1 + e^{-z}}
	•	뉴턴 방법에서 Hessian 사용됨

⸻

🔁 세션 흐름 요약
	1.	최적화 기본 구조 소개 (목적 함수, gradient, 최소화 개념)
	2.	극값 조건 → 기울기 조건 + 헤세 행렬 조건
	3.	Taylor 근사를 통해 왜 2차 정보가 중요한지 설명
	4.	로지스틱 회귀를 예제로, 실제 손실 함수 + gradient + Hessian 계산까지 다룸
	5.	다음 세션의 뉴턴 방법을 위한 기초 다지기!

⸻

다음은 Session 3: Iterative Algorithms for Continuous Optimization (46–89페이지) 들어갈게!
이 파트에서는 Gradient Descent, Newton’s Method, Quasi-Newton까지 다루니까 방금 배운 이론들이 실제로 어떻게 알고리즘이 되는지 이어진다!
곧바로 정리해줄게!