---
title: "Chapter01"
excerpt: "머신러닝 Chap01 전체 흐름"

categories:
  - MachineLearning
tags:
  - [Machine Learning, 머신러닝]

permalink: /categories/MachineLearning/Chapter01_MachineLearning

toc: true
toc_sticky: true
use_math: true

date: 2025-04-20
last_modified_at: 2025-04-20
---

# 📘 Session 1: Course Introduction (페이지 1–15)

## 📌 세션 개요

이 세션은 머신러닝의 기본 개념과 분류 체계를 소개하고,  
“무엇이 머신러닝인가?”라는 질문에 답하면서  
**지도학습(supervised)**, **비지도학습(unsupervised)**,  
그리고 **약한 지도학습(weakly supervised)**의 개념을 설명한다.  
또한 모델 설계 관점에서 머신러닝 방법을 **Generative vs Discriminative**,  
**Parametric vs Nonparametric**, **Linear vs Nonlinear** 등으로 분류한다.

---

## ✅ 핵심 개념 정리

### 🔹 What is Machine Learning?
- **정의**: 데이터를 바탕으로 정량적인 추론 및 예측을 수행하는 학문
- **배경**: 통계학, 인공지능, 신호처리 등에서 유래

---

### 🔹 Feature & Feature Vector
- **Feature**: 관측 대상의 수치적 특성 (예: 키, 몸무게 등)
- **Feature Vector**:
  \[
  x = \begin{bmatrix} x_1 \\ \vdots \\ x_d \end{bmatrix} \in \mathbb{R}^d
  \]
- **Synonyms**: data point, instance, example, signal, input 등

---

### 🔹 Categories of Learning
- **Supervised Learning**
  - 학습 데이터: \((x_1, y_1), \dots, (x_n, y_n)\)
  - 분류(classification), 회귀(regression)
- **Unsupervised Learning**
  - 정답(label) 없이 데이터 구조 분석
  - 클러스터링, 차원 축소, 밀도 추정 등
- **Weakly Supervised Learning**
  - 부분적으로 라벨된 데이터 사용 (예: semi-supervised)

---

### 🔹 Supervised Learning: Classification vs Regression
- **Classification**: 출력 \( y \in \{1, \dots, C\} \) (유한 클래스)
- **Regression**: 출력 \( y \in \mathbb{R} \) (연속적 값)

---

### 🔹 Modeling Paradigms in ML
- **Generative vs Discriminative**
  - Generative: 데이터의 전체 분포를 모델링 (예: Naive Bayes)
  - Discriminative: 결정 경계만 모델링 (예: Logistic Regression)
- **Parametric vs Nonparametric**
  - Parametric: 파라미터 수가 고정됨
  - Nonparametric: 데이터가 많아질수록 모델 복잡도 증가
- **Linear vs Nonlinear**
  - Linear: 출력이 입력의 선형함수
  - Nonlinear: 비선형 관계를 모델링

---

### 🔹 Practical Constraints
- **Scalability**: 대규모 데이터/모델에 적합해야 함
- **Privacy, Fairness, Safety**: 실제 응용에서 중요한 비기술적 제약

---

## 🔁 세션 흐름 요약

1. 머신러닝이 다루는 문제 정의와 배경 소개
2. Feature, Feature Vector 개념 및 용어 정리
3. 학습 방식 분류: 지도/비지도/약한 지도학습
4. 분류(Classification)와 회귀(Regression) 구분
5. 모델 설계 관점에서 여러 기준(Generative vs Discriminative 등) 소개
6. 실제 시스템 설계 시 고려해야 할 제약 조건까지 포괄적으로 다룸

---

🧠 이 세션은 최적화 문제로 들어가기 전, 머신러닝이라는 분야의 전반적인 구조를 잡아주는 역할을 함.



# 📗 Session 2: Unconstrained Optimization (페이지 16–45)

## 📌 세션 개요

이 세션은 머신러닝 모델 학습의 핵심인 **최적화 문제(Optimization Problem)**를 수학적으로 정의하고,  
기초적인 **미분 조건**, **Gradient**, **Hessian**, **Taylor Expansion** 등을 기반으로  
최소값을 찾기 위한 조건을 살펴본다.  
또한 로지스틱 회귀(Logistic Regression) 문제를 실제 예시로 들어 **손실 함수**, **gradient**, **Hessian** 계산법을 배운다.

---

# 📗 Session 2: Unconstrained Optimization (페이지 16–45)

## 📌 세션 개요

이 세션은 머신러닝 모델 학습의 핵심인 **최적화 문제(Optimization Problem)**를 수학적으로 정의하고,  
기초적인 **미분 조건**, **Gradient**, **Hessian**, **Taylor Expansion** 등을 기반으로  
최소값을 찾기 위한 조건을 살펴본다.  
또한 로지스틱 회귀(Logistic Regression) 문제를 실제 예시로 들어 **손실 함수**, **gradient**, **Hessian** 계산법을 배운다.

---

## ✅ 핵심 개념 정리

### 🔹 Optimization Problem (최적화 문제)
- **정의**:
  ```
  min_{x ∈ ℝ^d} f(x)
  ```
- **설명**: 목적 함수 f(x)를 최소화하는 x를 찾는 문제

---

### 🔹 Global vs. Local Minimum
- **Global Minimum**:
  ```
  f(x*) ≤ f(x), ∀ x ∈ ℝ^d
  ```
- **Local Minimum**:
  ```
  f(x*) ≤ f(x), ∀ x ∈ neighborhood(x*)
  ```

---

### 🔹 Gradient (기울기)
- **정의**: 목적 함수의 1차 미분값, 함수가 가장 가파르게 증가하는 방향
  ```
  ∇f(x) = [ ∂f/∂x₁, ..., ∂f/∂x_d ]ᵀ
  ```

---

### 🔹 Hessian (헤세 행렬)
- **정의**: 목적 함수의 2차 편미분값으로 구성된 대칭 행렬
  ```
  ∇²f(x) = [ ∂²f / ∂x_i ∂x_j ]_{i,j}
  ```

---

### 🔹 Optimality Conditions (최적 조건)
- **필요조건**:
  ```
  ∇f(x*) = 0
  ```
- **충분조건**:
  ```
  ∇²f(x*) ≻ 0  (positive definite)
  ```

---

### 🔹 Taylor Expansion (2차 테일러 근사)
- **식**:
  ```
  f(x + Δx) ≈ f(x) + ∇f(x)ᵀ Δx + ½ Δxᵀ ∇²f(x) Δx
  ```

---

### 🔹 Logistic Regression Loss (Negative Log Likelihood)
- **식**:
  ```
  min_θ ∑_{i=1}^n log(1 + exp(−yᵢ θᵀ xᵢ))
  ```

---

### 🔹 Regularized Logistic Regression
- **L2 정규화 포함**:
  ```
  min_θ ∑_{i=1}^n log(1 + exp(−yᵢ θᵀ xᵢ)) + λ ||θ||²
  ```

---

### 🔹 Gradient of Logistic Loss
- **식**:
  ```
  ∇θ f(θ) = ∑_{i=1}^n (σ(θᵀ xᵢ) − yᵢ) xᵢ
  ```
  where:
  ```
  σ(z) = 1 / (1 + exp(−z))
  ```

---

### 🔹 Hessian of Logistic Loss
- **식**:
  ```
  ∇²f(θ) = ∑_{i=1}^n σ(θᵀ xᵢ)(1 − σ(θᵀ xᵢ)) xᵢ xᵢᵀ
  ```

---

## 🔁 세션 흐름 요약

1. 머신러닝 학습 문제를 **최적화 문제**로 수학적으로 표현  
2. **Gradient**와 **Hessian**을 통해 극값 조건을 정의  
3. **Taylor 전개**로 최적화 방향과 양의 정부호 조건 도입  
4. 로지스틱 회귀를 실제 예로 들어 손실 함수 정의,  
   gradient 및 Hessian 계산 방법을 학습함  
5. 다음 세션(Iterative Algorithm)에서 Newton's method로 연결될 기초 완성

---

> 🧠 이 세션은 최적화 이론의 핵심 개념을 정립하고,  
> 다음 단계에서 반복 최적화 알고리즘을 적용할 수 있는 **수학적 도구**를 마련해줌.


# 📘 Session 3: Iterative Algorithms for Continuous Optimization (페이지 46–89)

## 📌 세션 개요

이 세션에서는 **최적화 알고리즘의 핵심 구조**를 이해하고,  
대표적인 반복 최적화 기법인  
- **Gradient Descent (GD)**  
- **Newton’s Method**  
- **Quasi-Newton (특히 BFGS)**  
의 개념과 수식, 구현 구조를 비교한다.  
또한 **Line Search**를 이용한 step size 조절과 각 알고리즘의 **수렴 속도 차이**도 함께 배운다.

---

## ✅ 핵심 개념 정리

### 🔹 General Form of Iterative Optimization
- **업데이트 식**:
  ```
  x^{(k+1)} = x^{(k)} + α^{(k)} p^{(k)}
  ```
- **설명**:
  - $begin:math:text$ p^{(k)} $end:math:text$: 이동 방향 (descent direction)
  - $begin:math:text$ α^{(k)} $end:math:text$: step size (learning rate)

---

### 🔹 Descent Direction (감소 방향)
- **조건**:
  ```
  ∇f(x)^T p < 0
  ```
- **설명**: 목적 함수를 줄일 수 있는 방향이면 descent direction이라 부름

---

### 🔹 Gradient Descent (GD)
- **업데이트 식**:
  ```
  x^{(k+1)} = x^{(k)} − α^{(k)} ∇f(x^{(k)})
  ```
- **설명**:
  - 가장 단순한 알고리즘
  - 계산은 쉽지만 수렴 속도는 느릴 수 있음

---

### 🔹 Newton's Method
- **업데이트 식**:
  ```
  x^{(k+1)} = x^{(k)} − [∇²f(x^{(k)})]⁻¹ ∇f(x^{(k)})
  ```
- **설명**:
  - 2차 테일러 근사를 이용한 빠른 수렴
  - 계산 복잡도는 높음 (Hessian 필요)

---

### 🔹 Quasi-Newton Method (e.g., BFGS)
- **업데이트 방향**:
  ```
  p^{(k)} = − B_k⁻¹ ∇f(x^{(k)})
  ```
- **BFGS 업데이트 식**:
  ```
  B_{k+1} = B_k + (y_k y_k^T) / (y_k^T s_k) − (B_k s_k s_k^T B_k) / (s_k^T B_k s_k)
  ```
  where:
  ```
  s_k = x^{(k+1)} − x^{(k)}
  y_k = ∇f(x^{(k+1)}) − ∇f(x^{(k)})
  ```
- **설명**:
  - Hessian을 계산하지 않고 근사
  - 실무에서 자주 사용됨 (예: SciPy `BFGS`)

---

### 🔹 Taylor Expansion (복습)
- **2차 근사 식**:
  ```
  f(x + Δx) ≈ f(x) + ∇f(x)^T Δx + ½ Δx^T ∇²f(x) Δx
  ```
- Newton Method는 이를 기반으로 파라미터 업데이트를 계산함

---

### 🔹 Line Search (Backtracking)
- **조건**:
  ```
  f(x + α p) ≤ f(x) + c α ∇f(x)^T p
  ```
- **설명**:
  - 적절한 step size α를 찾기 위해 반복적으로 줄여가며 만족 조건을 검사
  - 안정적인 수렴을 위해 모든 최적화 알고리즘에서 자주 사용

---

### 🔹 Convergence Rates
- **Gradient Descent**: Linear convergence  
- **Newton’s Method**: Quadratic convergence  
- **Quasi-Newton (BFGS)**: Superlinear convergence

---

## 🔁 세션 흐름 요약

1. 모든 반복 최적화 알고리즘의 **공통 구조**를 먼저 이해  
2. **Gradient Descent** → 단순하고 직관적이지만 느릴 수 있음  
3. **Newton’s Method** → 빠르지만 계산량 큼  
4. **Quasi-Newton (BFGS)** → 계산 효율과 수렴 속도의 절충안  
5. **Line Search**로 안정성 확보  
6. 각각의 방법이 **어떤 정보(gradient, Hessian)를 활용하는지**,  
   그리고 수렴 속도가 어떻게 다른지를 비교함

---

> 🧠 이 세션은 “어떻게 최적화할 것인가?”라는 실전적 질문에 답하면서,  
> 머신러닝 모델 학습의 기초 연산이 되는 알고리즘들의 구조를 정립해줌.


# 📙 Session 4: Nearest Neighbor Classifier (페이지 90–99)

## 📌 세션 개요

이 세션은 **K-최근접 이웃(K-Nearest Neighbor, K-NN)** 알고리즘을 다룬다.  
K-NN은 학습을 하지 않고, 단순히 **저장된 데이터**를 기준으로 가장 가까운 K개의 이웃의 라벨을 이용해  
예측을 수행하는 **비모수적(non-parametric)** 분류기다.  
또한 **거리 기반 분류의 한계점**과 **차원의 저주**, **bias-variance tradeoff**에 대해서도 설명한다.

---

## ✅ 핵심 개념 정리

### 🔹 1-Nearest Neighbor (1-NN)
- **정의**:
  ```
  ŷ(x) = y_{i*}, where i* = argmin_i ||x − x_i||_2
  ```
- **설명**: 입력 x에 대해 가장 가까운 학습 샘플의 라벨 y를 그대로 예측함

---

### 🔹 K-Nearest Neighbor (K-NN)
- **정의**:
  ```
  ŷ(x) = majority_vote { y_i | i ∈ 𝒩_K(x) }
  ```
  where:
  - $begin:math:text$ 𝒩_K(x) $end:math:text$: x의 K-최근접 이웃 인덱스 집합

- **설명**: K개의 가장 가까운 훈련 샘플을 찾고, 그들의 라벨을 기준으로 다수결로 예측

---

### 🔹 Distance Metrics (거리 척도)
- **Euclidean (L2)**:
  ```
  ||x − x_i||_2 = sqrt(∑_{j=1}^d (x_j − x_{ij})²)
  ```
- **Manhattan (L1)**:
  ```
  ∑ |x_j − x_{ij}|
  ```
- **Cosine distance**, **Mahalanobis distance** 등도 존재함

---

### 🔹 Curse of Dimensionality (차원의 저주)
- **설명**:
  - 차원이 높아질수록 모든 데이터 포인트들이 멀어진다  
  - K-NN처럼 거리 기반 알고리즘은 차원이 높을수록 정확도가 낮아질 수 있음

---

### 🔹 Bias-Variance Tradeoff in K-NN
- **설명**:
  - K가 작을수록 **모델이 민감**해짐 → **low bias, high variance**
  - K가 클수록 **모델이 부드러워짐** → **high bias, low variance**
  - 따라서 적절한 K 선택은 성능에 큰 영향을 준다

---

## 🔁 세션 흐름 요약

1. 가장 간단한 분류기인 **1-NN** 소개 → 가장 가까운 이웃의 라벨을 따름  
2. **K-NN** 일반화 → K개의 이웃 기반으로 예측  
3. 거리 계산 기준이 예측 성능에 큰 영향을 준다는 점 강조  
4. 고차원 데이터일수록 거리 기반 분류기의 성능 저하 (차원의 저주)  
5. K 값을 조절하면서 생기는 **bias-variance tradeoff**를 분석함

---

> 🧠 이 세션은 머신러닝의 **비모수적 학습(non-parametric learning)**의 기초를 제공하며,  
> 매우 단순하지만 강력한 K-NN 분류기의 작동 원리와 한계를 학습함.