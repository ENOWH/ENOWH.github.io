---
title: "Chapter01"
excerpt: "머신러닝 Chap01 전체 흐름"

categories:
  - MachineLearning
tags:
  - [Machine Learning, 머신러닝]

permalink: /categories/MachineLearning/Chapter01_MachineLearning

toc: true
toc_sticky: true

date: 2025-04-20
last_modified_at: 2025-04-20
---

## 📘 Chapter 01 - Session 1: Course Introduction (슬라이드 1–15)

### ✅ 1. 주요 개념 정리

| 개념 이름 | 설명 |
|-----------|------|
| **Machine Learning** | 데이터를 통해 정량적인 추론 및 예측을 수행하는 학문 |
| **Feature (특징)** | 관찰된 현상의 수치적 속성 |
| **Feature Vector** | 여러 특징을 담은 벡터. 일반적으로 \( \mathbf{x} \in \mathbb{R}^d \) |
| **Supervised Learning** | 입력과 정답(label)이 있는 데이터로부터 모델을 학습 |
| **Unsupervised Learning** | 레이블 없이 데이터의 구조를 파악 |
| **Weakly Supervised Learning** | 일부 레이블만 있거나, 노이즈가 있는 경우 등 |
| **Generative vs Discriminative Models** | 데이터의 전체 분포를 모델링(G), 결정 경계를 모델링(D) |
| **Parametric vs Nonparametric Models** | 모델의 복잡도와 유연성에 따른 분류 |
| **Linear vs Nonlinear Models** | 출력이 데이터에 대해 선형인지 여부 |
| **Constraints** | 실제 문제에서 고려해야 할 제약들 (예: Privacy, Fairness 등) |

---

### 🧠 2. 개념 ↔ 수식 정리

| 개념 이름 | 수식 |
|-----------|------|
| **Feature Vector** | $$ \mathbf{x} = \begin{bmatrix} x_1 \\ \vdots \\ x_d \end{bmatrix} \in \mathbb{R}^d $$ |
| **Supervised Learning (분류)** | $$ (\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n), \quad y_i \in \{1, \dots, C\} $$ |
| **Supervised Learning (회귀)** | $$ y_i \in \mathbb{R} $$ |
| **Generative Model** | $$ p(\mathbf{x}, y) = p(y) \cdot p(\mathbf{x} \mid y) $$ |
| **Discriminative Model** | $$ p(y \mid \mathbf{x}) \quad \text{또는} \quad f(\mathbf{x}) $$ |

---

### 🔁 3. 개념 흐름 설명

이 세션은 머신러닝의 전반적인 개요를 제공하며, 다음과 같은 흐름으로 전개됩니다:

1. **머신러닝이란?**
   - 데이터로부터 예측과 추론을 수행하는 학문
   - 통계학, 인공지능, 신호처리에서 유래하여 독립적인 학문 분야로 발전

2. **기본 구성 요소: Feature & Feature Vector**
   - Feature: 데이터를 구성하는 개별 속성
   - Feature Vector: 여러 feature로 구성된 벡터, \( \mathbf{x} \in \mathbb{R}^d \)

3. **학습 문제의 종류**
   - **Supervised Learning**: 입력 \( \mathbf{x} \) 와 정답 \( y \) 쌍을 이용해 모델을 학습
     - **Classification**: \( y \) 가 이산값 (예: MNIST 숫자 분류)
     - **Regression**: \( y \in \mathbb{R} \)
   - **Unsupervised Learning**: 정답 없이 \( \mathbf{x} \) 의 구조 분석
     - Clustering, Dimensionality Reduction, Density Estimation 등
   - **Weakly Supervised Learning**: 일부 레이블만 존재하거나 노이즈 포함된 학습

4. **모델 분류 기준**
   - **Generative vs Discriminative**
     - Generative: $$ p(\mathbf{x}, y) = p(y) \cdot p(\mathbf{x} \mid y) $$
     - Discriminative: $$ p(y \mid \mathbf{x}) \quad \text{또는} \quad f(\mathbf{x}) $$
   - **Parametric vs Nonparametric**
     - Parametric: 고정된 파라미터 수
     - Nonparametric: 데이터가 많아질수록 복잡도 증가
   - **Linear vs Nonlinear**
     - Linear: 출력이 입력에 대해 선형
     - Nonlinear: 비선형 구조 (예: Neural Networks)
   - **Constraints**
     - 실제 적용 시 고려: 연산 자원(Scalability), 사용자 프라이버시(Privacy), 공정성(Fairness), 안전성(Safety)

---


# 📘 Session 1: Course Introduction

## 🌱 개념 흐름 요약
- 머신러닝이란? → 데이터를 통해 정량적 추론 및 예측
- 문제 유형: Supervised / Unsupervised / Weakly Supervised
- 모델 분류 기준: Generative vs Discriminative, Parametric vs Nonparametric, Linear vs Nonlinear
- 현실 문제에서 중요한 제약 조건: Scalability, Privacy, Fairness, Safety

---

## 🔑 핵심 개념 & 수식 정리

### ✅ Feature & Feature Vector
- **Feature**: 관측된 현상의 측정 가능한 특성
- **Feature Vector**: 여러 feature의 벡터 표현  

$$
\mathbf{x} = \begin{bmatrix} x_1 \\ \vdots \\ x_d \end{bmatrix}, \quad \mathbf{x} \in \mathbb{R}^d
$$

- 다른 표현: attributes, predictors, covariates, examples, signals, inputs

---

### ✅ 머신러닝 문제 유형

#### 🔹 Supervised Learning
- 입력과 출력 쌍: $ (\mathbf{x}_i, y_i) $
- 목적: **예측 (Prediction)**
- 세부 유형:
  - **Classification**: $y$는 이산형 (e.g. MNIST)
  - **Regression**: $y$는 연속형

#### 🔹 Unsupervised Learning
- 출력 변수 없음
- 목적: **추론 (Inference)**
- 주요 방법:
  - Clustering
  - Dimensionality Reduction
  - Density Estimation

#### 🔹 Weakly Supervised Learning
- 라벨이 있는 데이터 + 없는 데이터 함께 사용
- 예시:
  - Semi-supervised Learning
  - Noisy Labels

---

### ✅ 모델 분류 기준

| 기준 | 설명 |
|------|------|
| **Generative** | 전체 확률 모델을 기반으로 함:<br> $$ p(\mathbf{x}, y) = p(y) \cdot p(\mathbf{x} \mid y) $$<br>데이터 생성 가능 |
| **Discriminative** | $$ p(y \mid \mathbf{x}) $$ 직접 모델링, 결정 경계에 집중 |
| **Parametric** | 고정된 수의 파라미터 사용 (데이터 크기와 무관) |
| **Nonparametric** | 데이터가 많아질수록 파라미터 수 증가 |
| **Linear** | 출력이 입력의 선형 함수 |
| **Nonlinear** | 선형이 아님 (예: 신경망) |

---

### ✅ 현실 제약 조건 (Constraints)
- **Scalability**: 대용량 데이터에 대한 연산 적응력
- **Privacy**: 개인 정보 보호
- **Fairness**: 편향 없는 의사결정
- **Safety**: 안전성 고려